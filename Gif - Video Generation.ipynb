# Dependencies(Needs)
!pip install diffusers transformers accelerate imageio[ffmpeg] opencv-python matplotlib # We have restart runtime after installation if needed

import torch
from diffusers import StableDiffusionImg2ImgPipeline
from PIL import Image
import os
import imageio
import numpy as np

from diffusers import StableDiffusionPipeline

# We have to Load the pipeline
pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16)
pipe.to("cuda")  # Use GPU for faster generation

def text_to_video(prompt, num_frames=16, height=512, width=512, steps=50, fps=8):
    frames = []
    seed = 42
    generator = torch.manual_seed(seed)

    for i in range(num_frames):
        # Generating individual frames
        image = pipe(prompt, num_inference_steps=steps, height=height, width=width, generator=generator).images[0]
        frames.append(np.array(image))

    # we have to Save the video
    video_path = "text_to_video.mp4"
    imageio.mimwrite(video_path, frames, fps=fps, macro_block_size=None)
    print(f"Video saved at {video_path}")
    return video_path

# Prompt
prompt = "SivaKarthikeyan Playing Hockey"

# Generating the video
video_path = text_to_video(prompt)

# Displaying the video
from IPython.display import Video
Video(video_path, embed=True)
